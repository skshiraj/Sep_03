{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "x=boston.data #independent variables\n",
    "y=boston.target #target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/35 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8949833162543306\n",
      "111.79067485000047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▎                                                                                | 1/35 [00:21<12:12, 21.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.835272992607234\n",
      "105.41784057813545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████▋                                                                              | 2/35 [00:41<11:34, 21.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0162640066120145\n",
      "90.96432988648495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███████                                                                            | 3/35 [01:01<11:02, 20.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.616378543893036\n",
      "91.71499763471718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█████████▍                                                                         | 4/35 [01:22<10:43, 20.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7961722222222196\n",
      "87.65652888275454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████▊                                                                       | 5/35 [01:43<10:27, 20.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1138151665058356\n",
      "109.80386225477366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|██████████████▏                                                                    | 6/35 [02:03<09:54, 20.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.774350684790699\n"
     ]
    }
   ],
   "source": [
    "#Step-1\n",
    "#creating 30 samples from the whole boston data points.\n",
    "Y_MSE_LIST=[]\n",
    "Y_OOB_LIST=[]\n",
    "for T in tqdm(range(35)):\n",
    "    T=T+1\n",
    "    col=np.arange(13)\n",
    "    x_num=np.arange(len(x))\n",
    "    y_num=np.arange(len(y))\n",
    "    col_set=[]\n",
    "    X_train=[]\n",
    "    X_test=[]\n",
    "    Y_train=[]\n",
    "    Y_test=[]\n",
    "    col_train_set=[]\n",
    "    for i in range(30):\n",
    "        i=i+1\n",
    "    #randomly choosing different feature for each sample\n",
    "        col_train, col_ignore= train_test_split(col, test_size=0.50,random_state=2*i*T)\n",
    "        col_train=np.sort(col_train)\n",
    "        col_train_set.append(col_train)\n",
    "    #X=x[:,col_train]\n",
    "        X_tr0, X_te0, y_tr0, y_te0 = train_test_split(x_num, y_num, test_size=0.40,random_state=3*i*T) #60% of x data\n",
    "        X_tr1, X_te1, y_tr1, y_te1 = train_test_split(X_tr0, y_tr0, test_size=0.33,random_state=2*i*T) #taking 40%of data from x_train(60% of x)\n",
    "    #addiing up the 60% and 40% values\n",
    "        X_tr_final=np.hstack((X_tr0,X_tr1))\n",
    "        y_tr_final=np.hstack((y_tr0,y_tr1))\n",
    "    #Corpus of 30 samples\n",
    "        X_train.append(X_tr_final)\n",
    "        X_test.append(X_te0)\n",
    "        Y_train.append(y_tr_final)\n",
    "        Y_test.append(y_te0)\n",
    "        \n",
    "#==============================================================================================================================        \n",
    "    #Step-2\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "    clf=DecisionTreeRegressor()\n",
    "    y_train_pred=[]\n",
    "    y_test_pred=[]\n",
    "    y_pred=[]\n",
    "    y_pred_test=[]\n",
    "    #y_pred corpus\n",
    "    for i in range(30):\n",
    "        y_total_pred=[]\n",
    "        clf.fit(x[:,col_train_set[i]][X_train[i]], y[Y_train[i]])\n",
    "        y_pred.append(clf.predict(x[:,col_train_set[i]]))\n",
    "#computing Average y_pre value    \n",
    "    y_sum=y_pred[0]\n",
    "    for j in range(len(y_pred)):\n",
    "        y_sum=+np.add(y_sum,y_pred[j])\n",
    "    y_pred_avg=np.true_divide(y_sum, 30)\n",
    "#computing MSE:\n",
    "    y_mse=np.subtract(y,y_pred_avg)#y-y_pred\n",
    "    y_mse_sqr=np.square(y_mse)#squaring the diff\n",
    "    y_mse_sum=0\n",
    "    for i in range(len(y_mse_sqr)):\n",
    "        y_mse_sum=y_mse_sum+y_mse_sqr[i]       \n",
    "    y_mse_final=y_mse_sum/len(y_mse_sqr)\n",
    "    print(y_mse_final)\n",
    "    Y_MSE_LIST.append(y_mse_final)\n",
    "#============================================================================================================================\n",
    "    #Step-3:\n",
    "    y_pred_oob=[]\n",
    "    countp=[]\n",
    "\n",
    "    X_trains=np.asarray(X_train)\n",
    "    for i in range(len(x)):\n",
    "        count=0\n",
    "        sum1=0\n",
    "        for j in range(30): \n",
    "            #print(i,j)\n",
    "            if i in X_test[j]:\n",
    "                #print(i,j)\n",
    "                count=count+1\n",
    "                #print(count)\n",
    "                clf.fit(x[:,col_train_set[j]][X_train[j]], y[Y_train[j]])\n",
    "                sum1=sum1+clf.predict((x[:,col_train_set[0]][0].reshape(1,-1)))\n",
    "        y_pred_oob.extend(sum1/count) \n",
    "    \n",
    "#computing OOB SCORE:\n",
    "    y_oob=np.subtract(y,y_pred_oob)#y-y_pred_oob\n",
    "    y_oob_sqr=np.square(y_oob)#squaring the diff\n",
    "    y_oob_sum=0\n",
    "#print(y_oob_sqr)\n",
    "    for i in range(len(y_oob_sqr)):\n",
    "        y_oob_sum=y_oob_sum+y_oob_sqr[i] \n",
    "    y_oob_final=y_oob_sum/(len(y_oob_sqr))\n",
    "    print((y_oob_final))\n",
    "    Y_OOB_LIST.append(y_oob_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
